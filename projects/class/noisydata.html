<html xmlns="http://www.w3.org/1999/xhtml">

<body>
    <div class="content_top"><span id="top"></span></div>
        <div class="content">
			<h1>Working With Noisy Data</h1>
            <p>Source code used in this post can be found <a href="https://github.com/BishKor/hw6">here</a>.</p>
			<p>Two files are provided. cetMax.txt contains the highest recorded temperature
            each month from 1878 to 2014 and cetMin.txt. the lowest recorded temperature. Both
            are records of centeral England. Both are formatted as follows.</p>
            <p>Year Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Avg</p>
		</div>
    <div class="content_top"><span id="data manipulation"></span></div>
        <div class="content">
			<h2>Reading in Data</h2>
			<p>Numpy contains an elegant function called genfromtxt. Used as follows.</p>
            <p>cmax = genfromtxt("cetMax.txt")</p>
            <p>In the case of the data files of this assignment, this function returns a 2D array
            in which each line is turned into an array with elements delimited by spaces. For convenience,
            a new array is created from the averages. Using a generator:</p>
            <p>avgs = [cmax[13] for i in cmax]</p>
		</div>
    <div class="content_top"><span id="Boxcar Smoothing"></span></div>
        <div class="content">
			<h2>Boxcar Smoothing</h2>
			<p>Boxcar smoothing, or moving average smoothing, has the effect of reducing noise
            by assigning a value in an array to be the average of the array element and its neighbors of
            a specified width away. For example, the 50-day
            <a href="http://www.investopedia.com/terms/m/movingaverage.asp">
            moving average</a>, used to evaluate asset prices, has a width of 50. Another python
            generator with numpy's mean function does the trick.</p>
            <p>bcmax = [np.mean(cmaxy[i:i+5]) for i in range(len(cmaxy)-5)]</p>
            <p>Notice in this operation a width of 5 was used. This has the effect of throwing out the
            first four data points in the data. bcmax goes then from 1882 to 2014.</p>
		</div>
    <div class="content_top"><span id="Gaussian Smoothing"></span></div>
        <div class="content">
			<h2>Gaussian Smoothing</h2>
			<p>Gaussian smoothing is slightly more intricate. One assume the statistical fluctiations
            within a system are gaussian. A standard deviation is determined via a characteristic
            time scale and one generates a gaussian kernel of a specified width. The function
            <a href="https://github.com/BishKor/hw6/blob/master/kernelgenerator.py">ggk</a>
            does the trick. The symmetry of the gaussian function suggests using an odd width
            kernel. Now the task is to convolve the kernel with the original data set. Numpy convolve
            does the trick.</p>
            <p>gkmax = np.convolve(cmaxy, ggk(1.5, 7), 'valid')</p>
		</div>
    <div class="content_top"><span id="Exponential Smoothing"></span></div>
        <div class="content">
			<h2>Exponential Smoothing</h2>
			<p>An iterative approach. The values of an array are reassigned per the following equation.</p>
            <img src="http://latex.codecogs.com/gif.latex?s_i=\alpha\cdot x_{t-1}+(1-\alpha)\cdot s_{i-1}" border="0"/>
            <p>This function <a href="https://github.com/BishKor/hw6/blob/master/exponentialsmoothing.py">exposmooth</a> returns
            an exponentially smoothed array.</p>
		</div>
    <div class="content_top"><span id="Plotting"></span></div>
        <div class="content">
			<h2>Plotting</h2>
                <img src="../../../images/tempsmoothing.png"
					 alt="Plot" style="width:1500px;height:900px">
		</div>
	<div class="content_top"><span id="Baseline"></span></div>
        <div class="content">
			<h2>Baseline</h2>
			<iframe width="420" height="315" src="https://www.youtube.com/embed/4_iC0MyIykM" frameborder="0" allowfullscreen></iframe>
			<p>Now that the mood has been set, let's begin. A baseline analogous to the origin of a coordinate system in a projectile motion
			problem. One must set the zero somehwere. However, the placement of a baseline may be suggestive of a behavior of data.
			For example, the following plot uses the average maximum temperature of the years 1968 to 1998. A baseline set at this level
			makes more certain the eye sees the upwards trend of the noisy data.</p>
			<img src="../../../images/baseline.png" alt="Plot" style="width:1500px;height:550px">
			
		</div>
	<div class="content_top"><span id="Baseline Optimization"></span></div>
        <div class="content">
			<h2>Baseline Optimization via Blind Parameter Searching</h2>
			<p>This <a href="https://github.com/BishKor/hw6/blob/master/blindanomoly.py">code</a> randomly assigns a begin year and an end year
			(at least 30 years after) and computes the average of the time between those years to be the baseline. It then computes the
			value of the anomoly. In this program, the baseline to display most prominently the anomoly means the maximization of the sum of
			the temperatures minus the baseline of years 2000-2010 minus the sum of the temperatures minus the baseline prior to 2000.</p>
			<img src="../../../images/optimizedanomoly.png" alt="Plot" style="width:500px;height:400px">
		</div>
	<div class="content_top"><span id="Season Optimization"></span></div>
        <div class="content">
			<h2>Seasonal Baselines</h2>
			<p><a href="https://github.com/BishKor/hw6/blob/master/seasons.py">seasons.py</a> randomly assigns a begin year and an end year
			(at least 30 years after) and computes the average of the time between those years to be the baseline. It then computes the
			value of the anomoly. In this program, the baseline to display most prominently the anomoly means the maximization of the sum of
			the temperatures minus the baseline of years 2000-2010 minus the sum of the temperatures minus the baseline prior to 2000.</p>
			<img src="../../../images/seasonsanomoly.png" alt="Plot" style="width:1500px;height:550px">
			
			<p>The baselines were: </br>
			summer max: 1980-2010</br>
			summer min: 1979-2009</br>
			winter max: 1978-2008</br>
			winter min: 1980-2010</p>
		</div>
	<div class="content_top"><span id="Poisson Stats"></span></div>
        <div class="content">
			<h2>Poisson Statistics</h2>
			<p>Using <a href="https://github.com/BishKor/hw6/blob/master/poissonstats.py">poissonstats.py</a>, I find that the probability of there being
			event of an average negative temerature to be 0.001, or .1%. Mighty unlikely.</p>
</body>
</html>